# PRP Execution Rules - Implementation and Validation Workflow

## Core Execution Workflow

**MANDATORY: Always follow this exact sequence:**

1. **Parse PRP** - Read and validate PRP document
2. **Analyze Dependencies** - Determine task execution order
3. **Check Prerequisites** - Verify environment and dependencies
4. **Execute Tasks** - Follow implementation blueprint step-by-step
5. **Validate Results** - Run validation loops at each level
6. **Update Progress** - Track completion status
7. **Generate Report** - Create execution summary

## PRP Parsing Standards

### Required PRP Elements

**Before execution, verify PRP contains:**
- Complete implementation blueprint
- Ordered task dependencies
- Pattern references with exact file paths
- Validation loop specifications
- Anti-pattern documentation
- Success criteria definitions

### Context Validation

**Ensure execution context is complete:**
- All referenced files exist and are accessible
- Pattern files contain expected structures
- Dependencies are properly installed
- Environment variables are configured
- Database connections are established

## Task Execution Standards

### Task Order Enforcement

**Execute tasks in dependency order:**
1. **Data Models** (Task 1) - Foundation for all other tasks
2. **Services** (Task 2) - Business logic implementation
3. **Tools/APIs** (Task 3) - External interface creation
4. **Integration** (Task 4) - System-wide connections
5. **Testing** (Task 5-6) - Quality assurance

### Implementation Patterns

**For each task, follow these steps:**
1. **Read pattern file** - Understand the structure to follow
2. **Create new file** - Use exact naming and placement
3. **Implement functionality** - Follow pattern exactly
4. **Run Level 1 validation** - Syntax, style, type checking
5. **Verify integration** - Ensure dependencies are satisfied
6. **Document changes** - Update any relevant documentation

### File Creation Standards

**When creating new files:**
- Use exact paths specified in PRP
- Follow naming conventions exactly
- Implement all required methods/classes
- Include proper imports and dependencies
- Add comprehensive error handling
- Follow existing code style

## Validation Loop Execution

### Level 1: Syntax & Style (Immediate)

**Run after each file creation:**
```bash
ruff check src/{new_files} --fix     # Auto-format and fix linting
mypy src/{new_files}                 # Type checking
ruff format src/{new_files}          # Consistent formatting
```

**Expected:** Zero errors. Fix all issues before proceeding.

### Level 2: Unit Tests (Component)

**Test each component as created:**
```bash
uv run pytest src/services/tests/test_{domain}_service.py -v
uv run pytest src/tools/tests/test_{action}_{resource}.py -v
```

**Expected:** All tests pass. Debug failures before continuing.

### Level 3: Integration Testing (System)

**Validate system integration:**
```bash
# Service startup
uv run python main.py &
sleep 3

# Health checks
curl -f http://localhost:8000/health

# Feature endpoints
curl -X POST http://localhost:8000/{endpoint} -H "Content-Type: application/json" -d '{"test": "data"}'
```

**Expected:** All integrations working, proper responses.

### Level 4: Creative Validation (Domain)

**Run domain-specific tests:**
```bash
# Performance testing
ab -n 100 -c 10 http://localhost:8000/{endpoint}

# Security scanning
bandit -r src

# Load testing
# wrk -t12 -c400 -d30s http://localhost:8000/{endpoint}
```

**Expected:** All creative validations pass.

## Error Handling During Execution

### Task Failure Recovery

**If a task fails:**
1. **Stop execution** immediately
2. **Analyze error** - Check logs, validation output
3. **Fix root cause** - Don't work around issues
4. **Re-run validation** - Ensure fix is complete
5. **Resume execution** - Continue from failed task

### Pattern Mismatch Handling

**If pattern doesn't match expected:**
1. **Analyze existing codebase** - Understand actual patterns
2. **Update PRP** - Document discovered patterns
3. **Adjust implementation** - Follow actual patterns
4. **Document changes** - Update pattern references
5. **Continue execution** - Resume with corrected approach

### Validation Failure Recovery

**If validation fails:**
1. **Read error output** - Understand what failed
2. **Fix implementation** - Address root cause
3. **Re-run validation** - Verify fix works
4. **Document lessons** - Update PRP if needed
5. **Continue execution** - Resume validation loop

## Progress Tracking

### Task Status Updates

**Track each task:**
- [ ] **Not Started** - Task identified but not begun
- [x] **In Progress** - Task actively being worked on
- [x] **Completed** - Task finished and validated
- [x] **Blocked** - Task waiting for dependency
- [x] **Failed** - Task encountered error (document reason)

### Completion Validation

**Task is complete when:**
- All implementation requirements met
- Level 1 validation passes
- Dependencies are satisfied
- Integration points work
- Documentation is updated

## Quality Assurance

### Code Quality Standards

**Maintain throughout execution:**
- Follow existing naming conventions
- Use established error handling patterns
- Maintain consistent code style
- Include comprehensive logging
- Add proper type hints
- Document complex logic

### Testing Standards

**Ensure comprehensive coverage:**
- Unit tests for all public methods
- Integration tests for workflows
- Error case testing
- Performance validation
- Security verification
- Edge case coverage

## Integration with Archon Workflow

**When using with Archon CE Template:**
1. **Workflow scripts** provide execution structure
2. **Advanced template** guides implementation
3. **Validation loops** ensure quality
4. **Cursor rules** enhance IDE experience
5. **Progress tracking** maintains visibility

## Success Metrics

**Execution is successful when:**
- All tasks completed successfully
- All validation levels passed
- Integration points working
- Performance requirements met
- Security requirements satisfied
- Documentation complete

## Final Validation

**Before marking complete:**
1. **Run full test suite** - All tests passing
2. **Validate all endpoints** - System integration working
3. **Check performance** - Meets specified requirements
4. **Verify security** - No vulnerabilities introduced
5. **Update documentation** - Reflects final implementation
6. **Archive PRP** - Mark as completed successfully

## Anti-Patterns During Execution

**Avoid these execution mistakes:**
- ❌ Skipping validation steps
- ❌ Working around errors instead of fixing
- ❌ Ignoring failing tests
- ❌ Deviating from established patterns
- ❌ Rushing through implementation
- ❌ Skipping documentation updates

## Recovery Procedures

**If execution goes off track:**
1. **Assess current state** - What's working, what's broken
2. **Identify deviation point** - Where did execution diverge
3. **Plan recovery** - How to get back on track
4. **Execute recovery** - Fix issues systematically
5. **Validate recovery** - Ensure system is stable
6. **Resume execution** - Continue from stable point

## Documentation Requirements

**During execution, maintain:**
- Task completion status
- Validation results
- Error logs and resolutions
- Pattern discoveries
- Integration notes
- Performance metrics

**After completion:**
- Final implementation summary
- Validation results summary
- Performance benchmarks
- Security assessment
- Deployment notes
- Maintenance requirements
---

---ndescription: PRP Execution Rules - Implementation and validation workflownglobs: ["**/*.md", "**/*.mdx", "**/*.txt"]nalwaysApply: falsen---nn# PRP Execution Rules - Implementation and Validation Workflownn## Core Execution Workflownn**MANDATORY: Always follow this exact sequence:**nn1. **Parse PRP** - Read and validate PRP documentn2. **Analyze Dependencies** - Determine task execution ordern3. **Check Prerequisites** - Verify environment and dependenciesn4. **Execute Tasks** - Follow implementation blueprint step-by-stepn5. **Validate Results** - Run validation loops at each leveln6. **Update Progress** - Track completion statusn7. **Generate Report** - Create execution summarynn## PRP Parsing Standardsnn### Required PRP Elementsnn**Before execution, verify PRP contains:**n- Complete implementation blueprintn- Ordered task dependenciesn- Pattern references with exact file pathsn- Validation loop specificationsn- Anti-pattern documentationn- Success criteria definitionsnn### Context Validationnn**Ensure execution context is complete:**n- All referenced files exist and are accessiblen- Pattern files contain expected structuresn- Dependencies are properly installedn- Environment variables are configuredn- Database connections are establishednn## Task Execution Standardsnn### Task Order Enforcementnn**Execute tasks in dependency order:**n1. **Data Models** (Task 1) - Foundation for all other tasksn2. **Services** (Task 2) - Business logic implementationn3. **Tools/APIs** (Task 3) - External interface creationn4. **Integration** (Task 4) - System-wide connectionsn5. **Testing** (Task 5-6) - Quality assurancenn### Implementation Patternsnn**For each task, follow these steps:**n1. **Read pattern file** - Understand the structure to follown2. **Create new file** - Use exact naming and placementn3. **Implement functionality** - Follow pattern exactlyn4. **Run Level 1 validation** - Syntax, style, type checkingn5. **Verify integration** - Ensure dependencies are satisfiedn6. **Document changes** - Update any relevant documentationnn### File Creation Standardsnn**When creating new files:**n- Use exact paths specified in PRPn- Follow naming conventions exactlyn- Implement all required methods/classesn- Include proper imports and dependenciesn- Add comprehensive error handlingn- Follow existing code stylenn## Validation Loop Executionnn### Level 1: Syntax & Style (Immediate)nn**Run after each file creation:**n```bashnruff check src/{new_files} --fix     # Auto-format and fix lintingnmypy src/{new_files}                 # Type checkingnruff format src/{new_files}          # Consistent formattingn```nn**Expected:** Zero errors. Fix all issues before proceeding.nn### Level 2: Unit Tests (Component)nn**Test each component as created:**n```bashnuv run pytest src/services/tests/test_{domain}_service.py -vnuv run pytest src/tools/tests/test_{action}_{resource}.py -vn```nn**Expected:** All tests pass. Debug failures before continuing.nn### Level 3: Integration Testing (System)nn**Validate system integration:**n```bashn# Service startupnuv run python main.py &nsleep 3nn# Health checksncurl -f http://localhost:8000/healthnn# Feature endpointsncurl -X POST http://localhost:8000/{endpoint} -H "Content-Type: application/json" -d '{"test": "data"}'n```nn**Expected:** All integrations working, proper responses.nn### Level 4: Creative Validation (Domain)nn**Run domain-specific tests:**n```bashn# Performance testingnab -n 100 -c 10 http://localhost:8000/{endpoint}nn# Security scanningnbandit -r src/nn# Load testingn# wrk -t12 -c400 -d30s http://localhost:8000/{endpoint}n```nn**Expected:** All creative validations pass.nn## Error Handling During Executionnn### Task Failure Recoverynn**If a task fails:**n1. **Stop execution** immediatelyn2. **Analyze error** - Check logs, validation outputn3. **Fix root cause** - Don't work around issuesn4. **Re-run validation** - Ensure fix is completen5. **Resume execution** - Continue from failed tasknn### Pattern Mismatch Handlingnn**If pattern doesn't match expected:**n1. **Analyze existing codebase** - Understand actual patternsn2. **Update PRP** - Document discovered patternsn3. **Adjust implementation** - Follow actual patternsn4. **Document changes** - Update pattern referencesn5. **Continue execution** - Resume with corrected approachnn### Validation Failure Recoverynn**If validation fails:**n1. **Read error output** - Understand what failedn2. **Fix implementation** - Address root causen3. **Re-run validation** - Verify fix worksn4. **Document lessons** - Update PRP if neededn5. **Continue execution** - Resume validation loopnn## Progress Trackingnn### Task Status Updatesnn**Track each task:**n- [ ] **Not Started** - Task identified but not begunn- [x] **In Progress** - Task actively being worked onn- [x] **Completed** - Task finished and validatedn- [x] **Blocked** - Task waiting for dependencyn- [x] **Failed** - Task encountered error (document reason)nn### Completion Validationnn**Task is complete when:**n- All implementation requirements metn- Level 1 validation passesn- Dependencies are satisfiedn- Integration points workn- Documentation is updatednn## Quality Assurancenn### Code Quality Standardsnn**Maintain throughout execution:**n- Follow existing naming conventionsn- Use established error handling patternsn- Maintain consistent code stylen- Include comprehensive loggingn- Add proper type hintsn- Document complex logicnn### Testing Standardsnn**Ensure comprehensive coverage:**n- Unit tests for all public methodsn- Integration tests for workflowsn- Error case testingn- Performance validationn- Security verificationn- Edge case coveragenn## Integration with Archon Workflownn**When using with Archon CE Template:**n1. **Workflow scripts** provide execution structuren2. **Advanced template** guides implementationn3. **Validation loops** ensure qualityn4. **Cursor rules** enhance IDE experiencen5. **Progress tracking** maintains visibilitynn## Success Metricsnn**Execution is successful when:**n- All tasks completed successfullyn- All validation levels passedn- Integration points workingn- Performance requirements metn- Security requirements satisfiedn- Documentation completenn## Final Validationnn**Before marking complete:**n1. **Run full test suite** - All tests passingn2. **Validate all endpoints** - System integration workingn3. **Check performance** - Meets specified requirementsn4. **Verify security** - No vulnerabilities introducedn5. **Update documentation** - Reflects final implementationn6. **Archive PRP** - Mark as completed successfullynn## Anti-Patterns During Executionnn**Avoid these execution mistakes:**n- ❌ Skipping validation stepsn- ❌ Working around errors instead of fixingn- ❌ Ignoring failing testsn- ❌ Deviating from established patternsn- ❌ Rushing through implementationn- ❌ Skipping documentation updatesnn## Recovery Proceduresnn**If execution goes off track:**n1. **Assess current state** - What's working, what's brokenn2. **Identify deviation point** - Where did execution divergen3. **Plan recovery** - How to get back on trackn4. **Execute recovery** - Fix issues systematicallyn5. **Validate recovery** - Ensure system is stablen6. **Resume execution** - Continue from stable pointnn## Documentation Requirementsnn**During execution, maintain:**n- Task completion statusn- Validation resultsn- Error logs and resolutionsn- Pattern discoveriesn- Integration notesn- Performance metricsnn**After completion:**n- Final implementation summaryn- Validation results summaryn- Performance benchmarksn- Security assessmentn- Deployment notesn- Maintenance requirements---ndescription: PRP Execution Rules - Implementation and validation workflownglobs: ["**/*.md", "**/*.mdx", "**/*.txt"]nalwaysApply: falsen---nn# PRP Execution Rules - Implementation and Validation Workflownn## Core Execution Workflownn**MANDATORY: Always follow this exact sequence:**nn1. **Parse PRP** - Read and validate PRP documentn2. **Analyze Dependencies** - Determine task execution ordern3. **Check Prerequisites** - Verify environment and dependenciesn4. **Execute Tasks** - Follow implementation blueprint step-by-stepn5. **Validate Results** - Run validation loops at each leveln6. **Update Progress** - Track completion statusn7. **Generate Report** - Create execution summarynn## PRP Parsing Standardsnn### Required PRP Elementsnn**Before execution, verify PRP contains:**n- Complete implementation blueprintn- Ordered task dependenciesn- Pattern references with exact file pathsn- Validation loop specificationsn- Anti-pattern documentationn- Success criteria definitionsnn### Context Validationnn**Ensure execution context is complete:**n- All referenced files exist and are accessiblen- Pattern files contain expected structuresn- Dependencies are properly installedn- Environment variables are configuredn- Database connections are establishednn## Task Execution Standardsnn### Task Order Enforcementnn**Execute tasks in dependency order:**n1. **Data Models** (Task 1) - Foundation for all other tasksn2. **Services** (Task 2) - Business logic implementationn3. **Tools/APIs** (Task 3) - External interface creationn4. **Integration** (Task 4) - System-wide connectionsn5. **Testing** (Task 5-6) - Quality assurancenn### Implementation Patternsnn**For each task, follow these steps:**n1. **Read pattern file** - Understand the structure to follown2. **Create new file** - Use exact naming and placementn3. **Implement functionality** - Follow pattern exactlyn4. **Run Level 1 validation** - Syntax, style, type checkingn5. **Verify integration** - Ensure dependencies are satisfiedn6. **Document changes** - Update any relevant documentationnn### File Creation Standardsnn**When creating new files:**n- Use exact paths specified in PRPn- Follow naming conventions exactlyn- Implement all required methods/classesn- Include proper imports and dependenciesn- Add comprehensive error handlingn- Follow existing code stylenn## Validation Loop Executionnn### Level 1: Syntax & Style (Immediate)nn**Run after each file creation:**n```bashnruff check src/{new_files} --fix     # Auto-format and fix lintingnmypy src/{new_files}                 # Type checkingnruff format src/{new_files}          # Consistent formattingn```nn**Expected:** Zero errors. Fix all issues before proceeding.nn### Level 2: Unit Tests (Component)nn**Test each component as created:**n```bashnuv run pytest src/services/tests/test_{domain}_service.py -vnuv run pytest src/tools/tests/test_{action}_{resource}.py -vn```nn**Expected:** All tests pass. Debug failures before continuing.nn### Level 3: Integration Testing (System)nn**Validate system integration:**n```bashn# Service startupnuv run python main.py &nsleep 3nn# Health checksncurl -f http://localhost:8000/healthnn# Feature endpointsncurl -X POST http://localhost:8000/{endpoint} -H "Content-Type: application/json" -d '{"test": "data"}'n```nn**Expected:** All integrations working, proper responses.nn### Level 4: Creative Validation (Domain)nn**Run domain-specific tests:**n```bashn# Performance testingnab -n 100 -c 10 http://localhost:8000/{endpoint}nn# Security scanningnbandit -r src/nn# Load testingn# wrk -t12 -c400 -d30s http://localhost:8000/{endpoint}n```nn**Expected:** All creative validations pass.nn## Error Handling During Executionnn### Task Failure Recoverynn**If a task fails:**n1. **Stop execution** immediatelyn2. **Analyze error** - Check logs, validation outputn3. **Fix root cause** - Don't work around issuesn4. **Re-run validation** - Ensure fix is completen5. **Resume execution** - Continue from failed tasknn### Pattern Mismatch Handlingnn**If pattern doesn't match expected:**n1. **Analyze existing codebase** - Understand actual patternsn2. **Update PRP** - Document discovered patternsn3. **Adjust implementation** - Follow actual patternsn4. **Document changes** - Update pattern referencesn5. **Continue execution** - Resume with corrected approachnn### Validation Failure Recoverynn**If validation fails:**n1. **Read error output** - Understand what failedn2. **Fix implementation** - Address root causen3. **Re-run validation** - Verify fix worksn4. **Document lessons** - Update PRP if neededn5. **Continue execution** - Resume validation loopnn## Progress Trackingnn### Task Status Updatesnn**Track each task:**n- [ ] **Not Started** - Task identified but not begunn- [x] **In Progress** - Task actively being worked onn- [x] **Completed** - Task finished and validatedn- [x] **Blocked** - Task waiting for dependencyn- [x] **Failed** - Task encountered error (document reason)nn### Completion Validationnn**Task is complete when:**n- All implementation requirements metn- Level 1 validation passesn- Dependencies are satisfiedn- Integration points workn- Documentation is updatednn## Quality Assurancenn### Code Quality Standardsnn**Maintain throughout execution:**n- Follow existing naming conventionsn- Use established error handling patternsn- Maintain consistent code stylen- Include comprehensive loggingn- Add proper type hintsn- Document complex logicnn### Testing Standardsnn**Ensure comprehensive coverage:**n- Unit tests for all public methodsn- Integration tests for workflowsn- Error case testingn- Performance validationn- Security verificationn- Edge case coveragenn## Integration with Archon Workflownn**When using with Archon CE Template:**n1. **Workflow scripts** provide execution structuren2. **Advanced template** guides implementationn3. **Validation loops** ensure qualityn4. **Cursor rules** enhance IDE experiencen5. **Progress tracking** maintains visibilitynn## Success Metricsnn**Execution is successful when:**n- All tasks completed successfullyn- All validation levels passedn- Integration points workingn- Performance requirements metn- Security requirements satisfiedn- Documentation completenn## Final Validationnn**Before marking complete:**n1. **Run full test suite** - All tests passingn2. **Validate all endpoints** - System integration workingn3. **Check performance** - Meets specified requirementsn4. **Verify security** - No vulnerabilities introducedn5. **Update documentation** - Reflects final implementationn6. **Archive PRP** - Mark as completed successfullynn## Anti-Patterns During Executionnn**Avoid these execution mistakes:**n- ❌ Skipping validation stepsn- ❌ Working around errors instead of fixingn- ❌ Ignoring failing testsn- ❌ Deviating from established patternsn- ❌ Rushing through implementationn- ❌ Skipping documentation updatesnn## Recovery Proceduresnn**If execution goes off track:**n1. **Assess current state** - What's working, what's brokenn2. **Identify deviation point** - Where did execution divergen3. **Plan recovery** - How to get back on trackn4. **Execute recovery** - Fix issues systematicallyn5. **Validate recovery** - Ensure system is stablen6. **Resume execution** - Continue from stable pointnn## Documentation Requirementsnn**During execution, maintain:**n- Task completion statusn- Validation resultsn- Error logs and resolutionsn- Pattern discoveriesn- Integration notesn- Performance metricsnn**After completion:**n- Final implementation summaryn- Validation results summaryn- Performance benchmarksn- Security assessmentn- Deployment notesn- Maintenance requirements